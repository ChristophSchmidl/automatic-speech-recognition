{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Convolutional Neural Network using Estimators\n",
    "\n",
    "* Based on this tutorial: https://www.tensorflow.org/tutorials/estimators/cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CS231n Convolutional Neural Networks for Visual Recognition: https://cs231n.github.io/convolutional-networks/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN MNIST Classifier\n",
    "\n",
    "Let's build a model to classify the images in the MNIST dataset using the following CNN architecture:\n",
    "\n",
    "1. **Convolutional Layer**: Applies 32 5x5 filters (extracting 5x5-pixel subregions), with ReLU activation function\n",
    "2. **Pooling Layer**: Performs max pooling with a 2x2 filter and stride of 2 (which specifies that pooled regions do not overlap)\n",
    "3. **Convolutional Layer**: Applies 64 5x5 filters, with ReLU activation function\n",
    "4. **Pooling Layer**: Again, performs max pooling with a 2x2 filter and stride of 2\n",
    "5. **Dense Layer**: 1,024 neurons, with dropout regularization rate of 0.4 (probability of 0.4 that any given element will be dropped during training)\n",
    "6. **Dense Layer** (Logits Layer): 10 neurons, one for each digit target class (0â€“9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2 and Pooling Layer #2\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Dense Layer\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits Layer\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])\n",
    "  }\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Load training and eval data\n",
    "((train_data, train_labels),\n",
    " (eval_data, eval_labels)) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_data = train_data/np.float32(255)\n",
    "train_labels = train_labels.astype(np.int32)  # not required\n",
    "\n",
    "eval_data = eval_data/np.float32(255)\n",
    "eval_labels = eval_labels.astype(np.int32)  # not required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "I0806 17:28:29.015386 4729447872 estimator.py:1790] Using default config.\n",
      "I0806 17:28:29.020840 4729447872 estimator.py:209] Using config: {'_model_dir': '/tmp/mnist_convnet_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0xb364eb908>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Create the Estimator\n",
    "mnist_classifier = tf.estimator.Estimator(\n",
    "    model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging for predictions\n",
    "tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors=tensors_to_log, every_n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0806 17:31:07.749806 4729447872 deprecation.py:323] From /Users/cschmidl/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0806 17:31:07.766159 4729447872 deprecation.py:323] From /Users/cschmidl/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "W0806 17:31:07.768745 4729447872 deprecation.py:323] From /Users/cschmidl/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0806 17:31:07.781781 4729447872 estimator.py:1145] Calling model_fn.\n",
      "W0806 17:31:07.787674 4729447872 deprecation.py:323] From <ipython-input-4-16a10fb7f348>:12: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0806 17:31:07.791439 4729447872 deprecation.py:506] From /Users/cschmidl/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0806 17:31:07.982160 4729447872 deprecation.py:323] From <ipython-input-4-16a10fb7f348>:15: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0806 17:31:08.091566 4729447872 deprecation.py:323] From <ipython-input-4-16a10fb7f348>:28: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0806 17:31:08.599300 4729447872 deprecation.py:323] From <ipython-input-4-16a10fb7f348>:30: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0806 17:31:08.673724 4729447872 deprecation.py:323] From /Users/cschmidl/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "I0806 17:31:08.773473 4729447872 estimator.py:1147] Done calling model_fn.\n",
      "I0806 17:31:08.775450 4729447872 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0806 17:31:08.884600 4729447872 monitored_session.py:240] Graph was finalized.\n",
      "I0806 17:31:09.030965 4729447872 session_manager.py:500] Running local_init_op.\n",
      "I0806 17:31:09.037212 4729447872 session_manager.py:502] Done running local_init_op.\n",
      "W0806 17:31:09.050143 4729447872 deprecation.py:323] From /Users/cschmidl/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:875: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "I0806 17:31:09.212390 4729447872 basic_session_run_hooks.py:606] Saving checkpoints for 0 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "I0806 17:31:09.570386 4729447872 basic_session_run_hooks.py:262] probabilities = [[0.09046187 0.10691246 0.09265386 0.10323584 0.10391237 0.10028831\n",
      "  0.11886816 0.10788604 0.0842568  0.09152426]\n",
      " [0.07836898 0.10208752 0.09739679 0.10668139 0.10441075 0.10181748\n",
      "  0.10701162 0.11014424 0.09400491 0.09807625]\n",
      " [0.09375129 0.11031049 0.10679259 0.10399143 0.11359648 0.10194449\n",
      "  0.10598531 0.09252287 0.084396   0.08670904]\n",
      " [0.09182871 0.10768814 0.1257331  0.10015405 0.10065553 0.08754379\n",
      "  0.09874687 0.09937593 0.08328727 0.10498658]\n",
      " [0.09855074 0.10571985 0.10450625 0.10563963 0.10255542 0.09556161\n",
      "  0.10644251 0.1021243  0.08416337 0.09473641]\n",
      " [0.09229227 0.11507869 0.10362379 0.09427813 0.11737711 0.08375917\n",
      "  0.09280487 0.11504265 0.09163546 0.09410776]\n",
      " [0.10040668 0.10883692 0.10338094 0.1101862  0.10324899 0.10333256\n",
      "  0.10707036 0.09459749 0.08151641 0.08742344]\n",
      " [0.09578266 0.10792556 0.09884964 0.1039748  0.10588372 0.09824165\n",
      "  0.10094111 0.10363141 0.08914594 0.09562358]\n",
      " [0.09263253 0.10365029 0.10683673 0.10482319 0.09169284 0.10104502\n",
      "  0.09901565 0.10716111 0.08931304 0.10382959]\n",
      " [0.08711623 0.10384537 0.11038028 0.10506517 0.09369755 0.10128855\n",
      "  0.10457423 0.10039946 0.08746272 0.10617045]\n",
      " [0.09563056 0.10706051 0.10692973 0.10169561 0.10774986 0.08798444\n",
      "  0.10938055 0.10715809 0.08310413 0.09330652]\n",
      " [0.10081231 0.10593057 0.09735227 0.10882866 0.09241774 0.10199486\n",
      "  0.10714304 0.09250674 0.09132694 0.10168684]\n",
      " [0.09726731 0.09649741 0.09943614 0.10098041 0.10148142 0.0916323\n",
      "  0.10363497 0.10468416 0.09598354 0.10840227]\n",
      " [0.08849943 0.10668895 0.1018293  0.09228282 0.11564194 0.09607964\n",
      "  0.10960355 0.10685035 0.08608653 0.09643751]\n",
      " [0.10155229 0.11546046 0.10268702 0.10155398 0.10362373 0.09992936\n",
      "  0.10080679 0.09560373 0.08871631 0.09006637]\n",
      " [0.0884812  0.10319041 0.10623822 0.10375781 0.11702643 0.09232598\n",
      "  0.10774627 0.1008585  0.09342445 0.0869507 ]\n",
      " [0.08837527 0.11256508 0.10845204 0.10357558 0.10006322 0.1016178\n",
      "  0.10906283 0.09349504 0.08728871 0.09550439]\n",
      " [0.09681695 0.11464155 0.10567611 0.10384434 0.09819482 0.09572832\n",
      "  0.10416178 0.1006344  0.08804514 0.09225666]\n",
      " [0.09443313 0.11047117 0.10803197 0.0973663  0.09770542 0.09536606\n",
      "  0.09917401 0.10297263 0.09245796 0.10202143]\n",
      " [0.10104135 0.1019247  0.10992233 0.09852628 0.10611585 0.10192097\n",
      "  0.10904152 0.08931227 0.08438825 0.09780653]\n",
      " [0.08534553 0.11244217 0.1066026  0.1008054  0.09905387 0.09146544\n",
      "  0.11330671 0.1018204  0.08304203 0.1061158 ]\n",
      " [0.08815291 0.11918817 0.1005066  0.10545807 0.09194206 0.10107238\n",
      "  0.10161355 0.10498086 0.09355448 0.09353099]\n",
      " [0.09562893 0.10344353 0.11278459 0.1002242  0.10432208 0.09997334\n",
      "  0.09680299 0.09609146 0.09367239 0.09705651]\n",
      " [0.08291521 0.10121868 0.09899985 0.10683753 0.10795605 0.10338794\n",
      "  0.09663046 0.11489166 0.08807775 0.09908486]\n",
      " [0.10292601 0.1079518  0.10736855 0.10278763 0.10818563 0.08970527\n",
      "  0.09840877 0.09526731 0.09157826 0.09582072]\n",
      " [0.08798274 0.09851159 0.11227699 0.09659912 0.10863113 0.09586518\n",
      "  0.11233611 0.10137724 0.08711774 0.09930223]\n",
      " [0.09474803 0.11257266 0.10286014 0.10301629 0.10638212 0.09808384\n",
      "  0.0945086  0.10170633 0.09815097 0.08797107]\n",
      " [0.09780869 0.10714558 0.10698406 0.10380962 0.09686982 0.09859069\n",
      "  0.09868945 0.09530432 0.08999559 0.10480219]\n",
      " [0.09574478 0.10824541 0.10724363 0.10546795 0.10581505 0.08744019\n",
      "  0.11047088 0.11058277 0.08139696 0.08759245]\n",
      " [0.09304304 0.10710163 0.10979912 0.10260621 0.1026047  0.09584647\n",
      "  0.11478543 0.09733966 0.07696255 0.09991111]\n",
      " [0.09414829 0.10690103 0.10738061 0.1074991  0.09679002 0.09985719\n",
      "  0.10227025 0.10276836 0.0900241  0.09236111]\n",
      " [0.09106095 0.09810628 0.12245258 0.10110108 0.11288422 0.09742852\n",
      "  0.09413521 0.09725631 0.08464828 0.10092656]\n",
      " [0.0909078  0.1044235  0.1052626  0.10124931 0.10230705 0.10743944\n",
      "  0.10548442 0.09544281 0.09082606 0.09665696]\n",
      " [0.08981976 0.10786536 0.11203372 0.10935432 0.09684893 0.09987985\n",
      "  0.09927508 0.10496323 0.0848032  0.09515648]\n",
      " [0.09551376 0.10798737 0.09163416 0.10451444 0.10878135 0.08829456\n",
      "  0.10689905 0.10296944 0.09945107 0.09395473]\n",
      " [0.09602842 0.10843583 0.10960494 0.10506915 0.10227734 0.10706424\n",
      "  0.09678393 0.09549269 0.08267988 0.09656361]\n",
      " [0.10065914 0.09742154 0.10724242 0.11142646 0.09842669 0.09658816\n",
      "  0.10183344 0.10135476 0.09011539 0.09493194]\n",
      " [0.10756183 0.11016653 0.09556945 0.09810711 0.10128701 0.08782782\n",
      "  0.1040412  0.10948841 0.08921949 0.09673118]\n",
      " [0.0945785  0.10763258 0.11210759 0.10309689 0.102671   0.09990217\n",
      "  0.09540252 0.0961722  0.08738993 0.10104667]\n",
      " [0.10227698 0.10340991 0.09956057 0.09396581 0.09957821 0.10035344\n",
      "  0.11192212 0.10285684 0.09064148 0.09543464]\n",
      " [0.09407115 0.10803321 0.09961747 0.10420593 0.10956813 0.09927758\n",
      "  0.10388765 0.09705883 0.08400362 0.10027648]\n",
      " [0.08711706 0.10477357 0.10586784 0.09950612 0.11916303 0.09737374\n",
      "  0.09429113 0.10560598 0.08681406 0.09948755]\n",
      " [0.08799296 0.1042961  0.11155125 0.10404162 0.10417908 0.09753701\n",
      "  0.09766075 0.09622071 0.08598508 0.11053544]\n",
      " [0.09381911 0.108864   0.10646039 0.09837327 0.10174193 0.09706046\n",
      "  0.10359429 0.09896088 0.09269436 0.09843127]\n",
      " [0.08855339 0.11374412 0.10110255 0.11692007 0.09699377 0.1040895\n",
      "  0.09636243 0.1034717  0.08473926 0.09402323]\n",
      " [0.09655562 0.10854341 0.10800456 0.09945214 0.10397165 0.09944406\n",
      "  0.10489502 0.09309132 0.08806214 0.09798007]\n",
      " [0.09798468 0.11829107 0.11773263 0.09348888 0.10286473 0.09397775\n",
      "  0.09064521 0.10270567 0.07983929 0.10247008]\n",
      " [0.09181067 0.10457483 0.10883671 0.10715726 0.10415307 0.09486949\n",
      "  0.11512086 0.09387984 0.08983547 0.08976185]\n",
      " [0.08774873 0.11263907 0.10264281 0.11221986 0.09797846 0.10684942\n",
      "  0.10517686 0.09235291 0.08907328 0.09331863]\n",
      " [0.092338   0.11408546 0.10977298 0.10180921 0.107704   0.09802427\n",
      "  0.10299285 0.10030901 0.08177531 0.09118893]\n",
      " [0.09522125 0.10998824 0.10434347 0.11542984 0.10283207 0.09112667\n",
      "  0.10629971 0.08481361 0.09351891 0.09642624]\n",
      " [0.10019166 0.10935299 0.10528547 0.1063747  0.10023815 0.09998524\n",
      "  0.10620309 0.09612594 0.08595847 0.0902843 ]\n",
      " [0.09836416 0.11205236 0.09630302 0.11055301 0.10512363 0.09489046\n",
      "  0.09702772 0.10378857 0.0829917  0.09890538]\n",
      " [0.10764099 0.11261375 0.10575236 0.10601195 0.09475917 0.10913251\n",
      "  0.09273601 0.09618757 0.08728274 0.08788286]\n",
      " [0.09151023 0.10820075 0.10259584 0.10286272 0.11356676 0.10441817\n",
      "  0.09958474 0.09989421 0.0818178  0.09554876]\n",
      " [0.10763439 0.10966801 0.10925035 0.10218383 0.10832398 0.08256678\n",
      "  0.10421448 0.09544725 0.08972201 0.09098892]\n",
      " [0.09943245 0.09616977 0.10520707 0.10422464 0.10079587 0.10142406\n",
      "  0.10577764 0.09977834 0.09123148 0.09595872]\n",
      " [0.1011193  0.10273115 0.11104503 0.10210297 0.10711125 0.08742853\n",
      "  0.0939397  0.10381058 0.08988899 0.10082261]\n",
      " [0.08887621 0.10389431 0.10340938 0.09758907 0.10730158 0.10048923\n",
      "  0.10357933 0.10792869 0.08553512 0.10139707]\n",
      " [0.09096091 0.10802542 0.10085765 0.11545857 0.09918258 0.10465886\n",
      "  0.10667451 0.10128534 0.08333809 0.08955809]\n",
      " [0.09264112 0.10051177 0.10272196 0.09505467 0.11641341 0.10694989\n",
      "  0.10366685 0.0995826  0.08953764 0.09292005]\n",
      " [0.09509075 0.1025181  0.10459035 0.1029786  0.10112882 0.09169512\n",
      "  0.11167104 0.10881763 0.08685338 0.09465623]\n",
      " [0.10181452 0.10871988 0.10958274 0.09751153 0.10319885 0.09421413\n",
      "  0.09807055 0.0994468  0.0882623  0.09917872]\n",
      " [0.09875838 0.10792118 0.10874761 0.10813763 0.10448007 0.08897983\n",
      "  0.10084813 0.10836406 0.08436542 0.08939762]\n",
      " [0.10254728 0.09825732 0.10332305 0.10039824 0.10591736 0.09698501\n",
      "  0.10589604 0.10135047 0.08729206 0.09803314]\n",
      " [0.0928276  0.09820767 0.10074054 0.09441356 0.10239381 0.10402467\n",
      "  0.10938285 0.10352176 0.09002336 0.10446411]\n",
      " [0.09093219 0.10293783 0.10507143 0.10868634 0.10138459 0.10164279\n",
      "  0.10491548 0.10262291 0.09306394 0.08874245]\n",
      " [0.09650433 0.09789198 0.10499294 0.10540192 0.10177237 0.09367479\n",
      "  0.10208803 0.10400733 0.08957744 0.10408887]\n",
      " [0.09543805 0.0991881  0.10341486 0.10448159 0.11333797 0.1009649\n",
      "  0.11599869 0.09455096 0.08040143 0.09222339]\n",
      " [0.09553263 0.1064793  0.11399736 0.10575803 0.10426462 0.09976871\n",
      "  0.09685712 0.10158932 0.0895016  0.0862513 ]\n",
      " [0.08947014 0.10948507 0.1029466  0.10444385 0.11010426 0.09657697\n",
      "  0.09853081 0.10146225 0.08003782 0.10694221]\n",
      " [0.09046    0.10847312 0.11133871 0.10866179 0.09451757 0.11035615\n",
      "  0.09580023 0.1032438  0.08772058 0.08942804]\n",
      " [0.08890636 0.09743118 0.12634523 0.09736091 0.104185   0.08968379\n",
      "  0.10361332 0.09928401 0.09070247 0.10248773]\n",
      " [0.08059534 0.10843995 0.09422996 0.09808685 0.10673823 0.11064798\n",
      "  0.10844691 0.1058774  0.08925099 0.0976864 ]\n",
      " [0.09649246 0.11163722 0.09819061 0.09740565 0.09728954 0.10281849\n",
      "  0.10524622 0.1039805  0.08514126 0.10179807]\n",
      " [0.09471137 0.09400827 0.09629983 0.09444342 0.1040177  0.09471343\n",
      "  0.11733768 0.10005297 0.09402307 0.11039224]\n",
      " [0.09520107 0.10474888 0.09721282 0.10417427 0.10672488 0.10196017\n",
      "  0.11059088 0.0931697  0.09241687 0.0938005 ]\n",
      " [0.09671679 0.10495635 0.10007842 0.116311   0.10097253 0.10112833\n",
      "  0.10821704 0.10068226 0.07919905 0.09173827]\n",
      " [0.09979188 0.11199184 0.10148893 0.09403165 0.09948334 0.10617702\n",
      "  0.10546266 0.10060478 0.08552931 0.09543857]\n",
      " [0.08670956 0.10099783 0.09310655 0.09484174 0.10757104 0.09896734\n",
      "  0.10657345 0.10630868 0.09171505 0.11320879]\n",
      " [0.08812824 0.10517599 0.11018536 0.10589589 0.10579828 0.10244774\n",
      "  0.09738853 0.09527541 0.08814695 0.10155766]\n",
      " [0.09089195 0.11393325 0.10942943 0.10437737 0.11262511 0.10017222\n",
      "  0.09845513 0.09384318 0.08796497 0.08830735]\n",
      " [0.09773812 0.1084066  0.12010217 0.10454646 0.10231531 0.09552677\n",
      "  0.10611667 0.08956278 0.0899406  0.08574457]\n",
      " [0.09580877 0.10359386 0.10453205 0.09978615 0.10275745 0.09820454\n",
      "  0.10250241 0.10230439 0.08725048 0.10325987]\n",
      " [0.09444919 0.10757434 0.09940664 0.10238431 0.10645301 0.0910656\n",
      "  0.10620443 0.10401355 0.08417936 0.10426957]\n",
      " [0.095684   0.10607243 0.1172051  0.09352659 0.11211824 0.09967181\n",
      "  0.09003384 0.10563975 0.08998165 0.09006655]\n",
      " [0.10416952 0.10652696 0.1019979  0.10166356 0.09661864 0.09639242\n",
      "  0.10672152 0.09699544 0.08618915 0.10272492]\n",
      " [0.09348287 0.10239863 0.08930998 0.10225249 0.10651276 0.10417105\n",
      "  0.10271311 0.10423337 0.09865793 0.09626783]\n",
      " [0.0962905  0.09904411 0.10142697 0.10475396 0.1040118  0.09430201\n",
      "  0.10768335 0.10298827 0.08581878 0.10368022]\n",
      " [0.09467345 0.11188058 0.1097449  0.09660441 0.10537812 0.09386726\n",
      "  0.09754484 0.10138406 0.09131879 0.09760352]\n",
      " [0.09507862 0.10693871 0.10380814 0.09094438 0.10660817 0.09684758\n",
      "  0.11150169 0.10017939 0.0900964  0.09799694]\n",
      " [0.09394632 0.10834055 0.10882083 0.10509385 0.09218444 0.10367066\n",
      "  0.1003307  0.09808489 0.08999085 0.09953693]\n",
      " [0.10025954 0.10499863 0.11814728 0.10002037 0.10269058 0.08881942\n",
      "  0.09340839 0.10544037 0.08852441 0.09769095]\n",
      " [0.09511947 0.10758679 0.1021985  0.10738631 0.10378405 0.0999238\n",
      "  0.09580975 0.1003575  0.09470488 0.09312887]\n",
      " [0.10035444 0.10421389 0.10622522 0.10645417 0.10145821 0.09481055\n",
      "  0.10599265 0.09713961 0.08583821 0.09751306]\n",
      " [0.08800097 0.10658328 0.10181085 0.103292   0.09666031 0.09972236\n",
      "  0.11603495 0.10468329 0.08032577 0.10288628]\n",
      " [0.09265778 0.10215412 0.11265144 0.09306881 0.10367621 0.09830222\n",
      "  0.10455025 0.10289913 0.08824637 0.10179364]\n",
      " [0.0956273  0.10653413 0.09268021 0.09388616 0.10625889 0.09645656\n",
      "  0.11212227 0.10062625 0.08450968 0.11129845]\n",
      " [0.09787136 0.11052427 0.09790129 0.108156   0.08147284 0.1083378\n",
      "  0.10084192 0.11186581 0.08901111 0.09401753]\n",
      " [0.09293344 0.10737472 0.09999087 0.10112008 0.10842922 0.08836749\n",
      "  0.10868593 0.10973411 0.08938324 0.09398086]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0806 17:31:09.571979 4729447872 basic_session_run_hooks.py:262] loss = 2.2947886, step = 1\n",
      "I0806 17:31:09.573289 4729447872 basic_session_run_hooks.py:606] Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "I0806 17:31:09.737036 4729447872 estimator.py:368] Loss for final step: 2.2947886.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0xb364eb6a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": train_data},\n",
    "    y=train_labels,\n",
    "    batch_size=100,\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "\n",
    "# train one step and display the probabilties\n",
    "mnist_classifier.train(\n",
    "    input_fn=train_input_fn,\n",
    "    steps=1,\n",
    "    hooks=[logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0806 17:45:41.789334 4729447872 estimator.py:1145] Calling model_fn.\n",
      "I0806 17:45:41.995869 4729447872 estimator.py:1147] Done calling model_fn.\n",
      "I0806 17:45:41.998392 4729447872 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0806 17:45:42.065080 4729447872 monitored_session.py:240] Graph was finalized.\n",
      "I0806 17:45:42.069709 4729447872 saver.py:1280] Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-1001\n",
      "I0806 17:45:42.112931 4729447872 session_manager.py:500] Running local_init_op.\n",
      "I0806 17:45:42.118672 4729447872 session_manager.py:502] Done running local_init_op.\n",
      "I0806 17:45:42.276324 4729447872 basic_session_run_hooks.py:606] Saving checkpoints for 1001 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "I0806 17:45:42.497745 4729447872 basic_session_run_hooks.py:262] loss = 2.0831218, step = 1002\n",
      "I0806 17:45:48.436609 4729447872 basic_session_run_hooks.py:692] global_step/sec: 16.8376\n",
      "I0806 17:45:48.437654 4729447872 basic_session_run_hooks.py:260] loss = 1.9834975, step = 1102 (5.940 sec)\n",
      "I0806 17:45:54.935212 4729447872 basic_session_run_hooks.py:692] global_step/sec: 15.3879\n",
      "I0806 17:45:54.936365 4729447872 basic_session_run_hooks.py:260] loss = 1.8026419, step = 1202 (6.499 sec)\n",
      "I0806 17:46:01.532333 4729447872 basic_session_run_hooks.py:692] global_step/sec: 15.1581\n",
      "I0806 17:46:01.533518 4729447872 basic_session_run_hooks.py:260] loss = 1.7555726, step = 1302 (6.597 sec)\n",
      "I0806 17:46:08.503842 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.3441\n",
      "I0806 17:46:08.505040 4729447872 basic_session_run_hooks.py:260] loss = 1.5277376, step = 1402 (6.972 sec)\n",
      "I0806 17:46:15.389610 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.5227\n",
      "I0806 17:46:15.390837 4729447872 basic_session_run_hooks.py:260] loss = 1.4338584, step = 1502 (6.886 sec)\n",
      "I0806 17:46:22.380490 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.3044\n",
      "I0806 17:46:22.381844 4729447872 basic_session_run_hooks.py:260] loss = 1.2916902, step = 1602 (6.991 sec)\n",
      "I0806 17:46:29.366351 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.3146\n",
      "I0806 17:46:29.367499 4729447872 basic_session_run_hooks.py:260] loss = 1.0873123, step = 1702 (6.986 sec)\n",
      "I0806 17:46:36.337749 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.3443\n",
      "I0806 17:46:36.338905 4729447872 basic_session_run_hooks.py:260] loss = 0.850284, step = 1802 (6.971 sec)\n",
      "I0806 17:46:43.370236 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.2197\n",
      "I0806 17:46:43.371454 4729447872 basic_session_run_hooks.py:260] loss = 0.9401384, step = 1902 (7.033 sec)\n",
      "I0806 17:46:50.454759 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.1153\n",
      "I0806 17:46:50.456056 4729447872 basic_session_run_hooks.py:260] loss = 1.0276701, step = 2002 (7.085 sec)\n",
      "I0806 17:46:57.614537 4729447872 basic_session_run_hooks.py:692] global_step/sec: 13.9669\n",
      "I0806 17:46:57.615671 4729447872 basic_session_run_hooks.py:260] loss = 0.7059645, step = 2102 (7.160 sec)\n",
      "I0806 17:47:04.495898 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.532\n",
      "I0806 17:47:04.497053 4729447872 basic_session_run_hooks.py:260] loss = 0.5775192, step = 2202 (6.881 sec)\n",
      "I0806 17:47:11.387749 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.5099\n",
      "I0806 17:47:11.388890 4729447872 basic_session_run_hooks.py:260] loss = 0.6364137, step = 2302 (6.892 sec)\n",
      "I0806 17:47:18.236352 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.6015\n",
      "I0806 17:47:18.237521 4729447872 basic_session_run_hooks.py:260] loss = 0.52750176, step = 2402 (6.849 sec)\n",
      "I0806 17:47:25.040099 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.6978\n",
      "I0806 17:47:25.041208 4729447872 basic_session_run_hooks.py:260] loss = 0.71829516, step = 2502 (6.804 sec)\n",
      "I0806 17:47:31.986833 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.3952\n",
      "I0806 17:47:31.987980 4729447872 basic_session_run_hooks.py:260] loss = 0.4519994, step = 2602 (6.947 sec)\n",
      "I0806 17:47:38.824368 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.6252\n",
      "I0806 17:47:38.825582 4729447872 basic_session_run_hooks.py:260] loss = 0.501121, step = 2702 (6.838 sec)\n",
      "I0806 17:47:45.626079 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.7022\n",
      "I0806 17:47:45.627846 4729447872 basic_session_run_hooks.py:260] loss = 0.41843846, step = 2802 (6.802 sec)\n",
      "I0806 17:47:52.466405 4729447872 basic_session_run_hooks.py:692] global_step/sec: 14.6192\n",
      "I0806 17:47:52.467662 4729447872 basic_session_run_hooks.py:260] loss = 0.551224, step = 2902 (6.840 sec)\n",
      "I0806 17:47:59.200242 4729447872 basic_session_run_hooks.py:606] Saving checkpoints for 3001 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "I0806 17:47:59.348628 4729447872 estimator.py:368] Loss for final step: 0.3624467.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow_estimator.python.estimator.estimator.Estimator at 0xb364eb6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_classifier.train(input_fn=train_input_fn, steps=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0806 17:54:39.250916 4729447872 estimator.py:1145] Calling model_fn.\n",
      "I0806 17:54:39.341981 4729447872 estimator.py:1147] Done calling model_fn.\n",
      "I0806 17:54:39.361567 4729447872 evaluation.py:255] Starting evaluation at 2019-08-06T17:54:39Z\n",
      "I0806 17:54:39.428659 4729447872 monitored_session.py:240] Graph was finalized.\n",
      "I0806 17:54:39.430938 4729447872 saver.py:1280] Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-3001\n",
      "I0806 17:54:39.475301 4729447872 session_manager.py:500] Running local_init_op.\n",
      "I0806 17:54:39.483315 4729447872 session_manager.py:502] Done running local_init_op.\n",
      "I0806 17:54:41.065331 4729447872 evaluation.py:275] Finished evaluation at 2019-08-06-17:54:41\n",
      "I0806 17:54:41.066061 4729447872 estimator.py:2039] Saving dict for global step 3001: accuracy = 0.8998, global_step = 3001, loss = 0.3958079\n",
      "I0806 17:54:41.068660 4729447872 estimator.py:2099] Saving 'checkpoint_path' summary for global step 3001: /tmp/mnist_convnet_model/model.ckpt-3001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8998, 'loss': 0.3958079, 'global_step': 3001}\n"
     ]
    }
   ],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": eval_data},\n",
    "    y=eval_labels,\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "print(eval_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
