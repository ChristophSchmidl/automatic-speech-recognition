{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a TF Estimator end-to-end baseline solution\n",
    "\n",
    "For local run\n",
    "\n",
    "Tested with\n",
    "\n",
    "~~~~\n",
    "numpy==1.13.3\n",
    "scipy==0.19.1\n",
    "tensorflow-gpu==1.4.0\n",
    "tqdm\n",
    "~~~~\n",
    "\n",
    "I want to show usage of Estimators with custom python datagenerators.\n",
    "\n",
    "Detailed documentation you can find at https://www.tensorflow.org/api_docs/python/tf/estimator/Estimator\n",
    "\n",
    "I also recommend to read source code https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py\n",
    "\n",
    "Suppose we have following project structure:\n",
    "\n",
    "\n",
    "```\n",
    ".\n",
    "├── data\n",
    "│   ├── test            # extracted\n",
    "│   │   └── audio          # all test\n",
    "│   ├── test.7z         # downloaded\n",
    "│   ├── train           # extracted\n",
    "│   │   ├── audio          # folder with all train command/file.wav\n",
    "│   │   ├── LICENSE\n",
    "│   │   ├── README.md\n",
    "│   │   ├── testing_list.txt\n",
    "│   │   └── validation_list.txt\n",
    "│   └── train.7z         # downloaded\n",
    "├── kernel.ipynb      # this ipynb  \n",
    "└── model-k           # folder for model, checkpoints, logs and submission.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 57929 train and 6798 val samples\n"
     ]
    }
   ],
   "source": [
    "DATADIR = '../data' # unzipped train and test data\n",
    "OUTDIR = './model-k' # just a random name\n",
    "# Data Loading\n",
    "import os\n",
    "import re\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "POSSIBLE_LABELS = 'yes no up down left right on off stop go silence unknown'.split()\n",
    "id2name = {i: name for i, name in enumerate(POSSIBLE_LABELS)}\n",
    "name2id = {name: i for i, name in id2name.items()}\n",
    "\n",
    "\n",
    "def load_data(data_dir):\n",
    "    \"\"\" Return 2 lists of tuples:\n",
    "    [(class_id, user_id, path), ...] for train\n",
    "    [(class_id, user_id, path), ...] for validation\n",
    "    \"\"\"\n",
    "    # Just a simple regexp for paths with three groups:\n",
    "    # prefix, label, user_id\n",
    "    pattern = re.compile(\"(.+\\/)?(\\w+)\\/([^_]+)_.+wav\")\n",
    "    all_files = glob(os.path.join(data_dir, 'train/audio/*/*wav'))\n",
    "\n",
    "    with open(os.path.join(data_dir, 'train/validation_list.txt'), 'r') as fin:\n",
    "        validation_files = fin.readlines()\n",
    "    valset = set()\n",
    "    for entry in validation_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            valset.add(r.group(3))\n",
    "\n",
    "    possible = set(POSSIBLE_LABELS)\n",
    "    train, val = [], []\n",
    "    for entry in all_files:\n",
    "        r = re.match(pattern, entry)\n",
    "        if r:\n",
    "            label, uid = r.group(2), r.group(3)\n",
    "            if label == '_background_noise_':\n",
    "                label = 'silence'\n",
    "            if label not in possible:\n",
    "                label = 'unknown'\n",
    "\n",
    "            label_id = name2id[label]\n",
    "\n",
    "            sample = (label_id, uid, entry)\n",
    "            if uid in valset:\n",
    "                val.append(sample)\n",
    "            else:\n",
    "                train.append(sample)\n",
    "\n",
    "    print('There are {} train and {} val samples'.format(len(train), len(val)))\n",
    "    return train, val\n",
    "\n",
    "trainset, valset = load_data(DATADIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let me introduce pythonic datagenerator. It is just a python/numpy/... function **without tf** that yields dicts such that\n",
    "\n",
    "```\n",
    "{\n",
    "  'x': np.array(...),\n",
    "  'str_key': np.string_(...),\n",
    "  'label': np.int32(...),\n",
    "}\n",
    "```\n",
    "\n",
    "Be sure, every value in this dict has .dtype method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def data_generator(data, params, mode='train'):\n",
    "    def generator():\n",
    "        if mode == 'train':\n",
    "            np.random.shuffle(data)\n",
    "        # Feel free to add any augmentation\n",
    "        for (label_id, uid, fname) in data:\n",
    "            try:\n",
    "                _, wav = wavfile.read(fname)\n",
    "                wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "\n",
    "                L = 16000  # be aware, some files are shorter than 1 sec!\n",
    "                if len(wav) < L:\n",
    "                    continue\n",
    "                # let's generate more silence!\n",
    "                samples_per_file = 1 if label_id != name2id['silence'] else 20\n",
    "                for _ in range(samples_per_file):\n",
    "                    if len(wav) > L:\n",
    "                        beg = np.random.randint(0, len(wav) - L)\n",
    "                    else:\n",
    "                        beg = 0\n",
    "                    yield dict(\n",
    "                        target=np.int32(label_id),\n",
    "                        wav=wav[beg: beg + L],\n",
    "                    )\n",
    "            except Exception as err:\n",
    "                print(err, label_id, uid, fname)\n",
    "\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we have spectrograms and want to write feature extractor that produces logits.\n",
    "\n",
    "Let's write some simple net, treat sound as a picture.\n",
    "\n",
    "**Spectrograms** (input x) have shape ```(batch_size, time_frames, freq_bins, 2)```.\n",
    "\n",
    "**Logits** is a tensor with shape ```(batch_size, num_classes)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import layers\n",
    "\n",
    "def baseline(x, params, is_training):\n",
    "    x = layers.batch_norm(x, is_training=is_training)\n",
    "    for i in range(4):\n",
    "        x = layers.conv2d(\n",
    "            x, 16 * (2 ** i), 3, 1,\n",
    "            activation_fn=tf.nn.elu,\n",
    "            normalizer_fn=layers.batch_norm if params.use_batch_norm else None,\n",
    "            normalizer_params={'is_training': is_training}\n",
    "        )\n",
    "        x = layers.max_pool2d(x, 2, 2)\n",
    "\n",
    "    # just take two kind of pooling and then mix them, why not :)\n",
    "    mpool = tf.reduce_max(x, axis=[1, 2], keep_dims=True)\n",
    "    apool = tf.reduce_mean(x, axis=[1, 2], keep_dims=True)\n",
    "\n",
    "    x = 0.5 * (mpool + apool)\n",
    "    # we can use conv2d 1x1 instead of dense\n",
    "    x = layers.conv2d(x, 128, 1, 1, activation_fn=tf.nn.elu)\n",
    "    x = tf.nn.dropout(x, keep_prob=params.keep_prob if is_training else 1.0)\n",
    "    \n",
    "    # again conv2d 1x1 instead of dense layer\n",
    "    logits = layers.conv2d(x, params.num_classes, 1, 1, activation_fn=None)\n",
    "    return tf.squeeze(logits, [1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to write a model handler for three regimes:\n",
    "\n",
    "* train\n",
    "* eval\n",
    "* predict\n",
    "\n",
    "Loss function, train_op, additional metrics and summaries should be defined.\n",
    "\n",
    "Also, we need to convert sound waveform into spectrograms (we could do it with numpy/scipy/librosa in data generator, but TF has new signal processing API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import signal\n",
    "\n",
    "# features is a dict with keys: tensors from our datagenerator\n",
    "# labels also were in features, but excluded in generator_input_fn by target_key\n",
    "\n",
    "def model_handler(features, labels, mode, params, config):\n",
    "    # Im really like to use make_template instead of variable_scopes and re-usage\n",
    "    extractor = tf.make_template(\n",
    "        'extractor', baseline,\n",
    "        create_scope_now_=True,\n",
    "    )\n",
    "    # wav is a waveform signal with shape (16000, )\n",
    "    wav = features['wav']\n",
    "    # we want to compute spectograms by means of short time fourier transform:\n",
    "    specgram = signal.stft(\n",
    "        wav,\n",
    "        400,  # 16000 [samples per second] * 0.025 [s] -- default stft window frame\n",
    "        160,  # 16000 * 0.010 -- default stride\n",
    "    )\n",
    "    # specgram is a complex tensor, so split it into abs and phase parts:\n",
    "    phase = tf.angle(specgram) / np.pi\n",
    "    # log(1 + abs) is a default transformation for energy units\n",
    "    amp = tf.log1p(tf.abs(specgram))\n",
    "    \n",
    "    x = tf.stack([amp, phase], axis=3) # shape is [bs, time, freq_bins, 2]\n",
    "    x = tf.to_float(x)  # we want to have float32, not float64\n",
    "\n",
    "    logits = extractor(x, params, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "        # some lr tuner, you could use move interesting functions\n",
    "        def learning_rate_decay_fn(learning_rate, global_step):\n",
    "            return tf.train.exponential_decay(\n",
    "                learning_rate, global_step, decay_steps=10000, decay_rate=0.99)\n",
    "\n",
    "        train_op = tf.contrib.layers.optimize_loss(\n",
    "            loss=loss,\n",
    "            global_step=tf.contrib.framework.get_global_step(),\n",
    "            learning_rate=params.learning_rate,\n",
    "            optimizer=lambda lr: tf.train.MomentumOptimizer(lr, 0.9, use_nesterov=True),\n",
    "            learning_rate_decay_fn=learning_rate_decay_fn,\n",
    "            clip_gradients=params.clip_gradients,\n",
    "            variables=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            train_op=train_op,\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        prediction = tf.argmax(logits, axis=-1)\n",
    "        acc, acc_op = tf.metrics.mean_per_class_accuracy(\n",
    "            labels, prediction, params.num_classes)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(labels=labels, logits=logits))\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            loss=loss,\n",
    "            eval_metric_ops=dict(\n",
    "                acc=(acc, acc_op),\n",
    "            )\n",
    "        )\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            'label': tf.argmax(logits, axis=-1),  # for probability just take tf.nn.softmax()\n",
    "            'sample': features['sample'], # it's a hack for simplicity\n",
    "        }\n",
    "        specs = dict(\n",
    "            mode=mode,\n",
    "            predictions=predictions,\n",
    "        )\n",
    "    return tf.estimator.EstimatorSpec(**specs)\n",
    "\n",
    "\n",
    "def create_model(config=None, hparams=None):\n",
    "    return tf.estimator.Estimator(\n",
    "        model_fn=model_handler,\n",
    "        config=config,\n",
    "        params=hparams,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some params. Move model hyperparams (optimizer, extractor, num of layers, activation fn, ...) here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-7-363407e190c9>:15: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "When switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\n"
     ]
    }
   ],
   "source": [
    "params=dict(\n",
    "    seed=2018,\n",
    "    batch_size=64,\n",
    "    keep_prob=0.5,\n",
    "    learning_rate=1e-3,\n",
    "    clip_gradients=15.0,\n",
    "    use_batch_norm=True,\n",
    "    num_classes=len(POSSIBLE_LABELS),\n",
    ")\n",
    "\n",
    "hparams = tf.contrib.training.HParams(**params)\n",
    "os.makedirs(os.path.join(OUTDIR, 'eval'), exist_ok=True)\n",
    "model_dir = OUTDIR\n",
    "\n",
    "run_config = tf.contrib.learn.RunConfig(model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's run training!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-330cd668f47e>:8: generator_input_fn (from tensorflow.contrib.learn.python.learn.learn_io.generator_io) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data.\n",
      "WARNING:tensorflow:From <ipython-input-8-330cd668f47e>:34: run (from tensorflow.contrib.learn.python.learn.learn_runner) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.estimator.train_and_evaluate.\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5aa91974a8>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './model-k'}\n",
      "WARNING:tensorflow:From <ipython-input-8-330cd668f47e>:26: Experiment.__init__ (from tensorflow.contrib.learn.python.learn.experiment) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.estimator.train_and_evaluate. You will also have to convert to a tf.estimator.Estimator.\n",
      "WARNING:tensorflow:RunConfig.uid (from tensorflow.contrib.learn.python.learn.estimators.run_config) is experimental and may change or be removed at any time, and without warning.\n",
      "WARNING:tensorflow:Experiment.continuous_train_and_eval (from tensorflow.contrib.learn.python.learn.experiment) is experimental and may change or be removed at any time, and without warning.\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From <ipython-input-6-2bae007bba27>:26: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From <ipython-input-5-9bfa8fa3d61a>:16: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From <ipython-input-5-9bfa8fa3d61a>:22: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-6-2bae007bba27>:40: get_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please switch to tf.train.get_global_step\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/monitored_session.py:809: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 6.565032, step = 0\n",
      "INFO:tensorflow:global_step/sec: 23.307\n",
      "INFO:tensorflow:loss = 1.7329886, step = 100 (4.293 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3667\n",
      "INFO:tensorflow:loss = 1.1898205, step = 200 (4.103 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cs/anaconda3/lib/python3.7/site-packages/scipy/io/wavfile.py:273: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  WavFileWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.2846\n",
      "INFO:tensorflow:loss = 1.3337922, step = 300 (4.118 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1337\n",
      "INFO:tensorflow:loss = 1.0936182, step = 400 (4.143 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0979\n",
      "INFO:tensorflow:loss = 1.1033119, step = 500 (4.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6984\n",
      "INFO:tensorflow:loss = 1.1183573, step = 600 (4.220 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.6454\n",
      "INFO:tensorflow:loss = 0.98763216, step = 700 (4.229 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.4584\n",
      "INFO:tensorflow:loss = 0.756913, step = 800 (4.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.5045\n",
      "INFO:tensorflow:loss = 0.72922885, step = 900 (4.255 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5589514.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/metrics_impl.py:1022: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:50:46Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:50:49\n",
      "INFO:tensorflow:Saving dict for global step 1000: acc = 0.1487874, global_step = 1000, loss = 1.2641674\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ./model-k/model.ckpt-1000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-1000\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1070: get_checkpoint_mtimes (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file utilities to get mtimes.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.70138276, step = 1000\n",
      "INFO:tensorflow:global_step/sec: 23.5525\n",
      "INFO:tensorflow:loss = 0.7594317, step = 1100 (4.247 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3704\n",
      "INFO:tensorflow:loss = 0.48487324, step = 1200 (4.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3115\n",
      "INFO:tensorflow:loss = 0.7277067, step = 1300 (4.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3121\n",
      "INFO:tensorflow:loss = 0.7265692, step = 1400 (4.113 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4414\n",
      "INFO:tensorflow:loss = 0.37095627, step = 1500 (4.092 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.41\n",
      "INFO:tensorflow:loss = 0.71582496, step = 1600 (4.097 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.415\n",
      "INFO:tensorflow:loss = 0.5160989, step = 1700 (4.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2129\n",
      "INFO:tensorflow:loss = 0.78456324, step = 1800 (4.130 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2395\n",
      "INFO:tensorflow:loss = 0.46656626, step = 1900 (4.125 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.5547035.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:51:32Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:51:35\n",
      "INFO:tensorflow:Saving dict for global step 2000: acc = 0.16575162, global_step = 2000, loss = 0.9201458\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: ./model-k/model.ckpt-2000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.48676932, step = 2000\n",
      "INFO:tensorflow:global_step/sec: 24.0721\n",
      "INFO:tensorflow:loss = 0.5149897, step = 2100 (4.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.355\n",
      "INFO:tensorflow:loss = 0.54326195, step = 2200 (4.106 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9247\n",
      "INFO:tensorflow:loss = 0.5245217, step = 2300 (4.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0343\n",
      "INFO:tensorflow:loss = 0.58012366, step = 2400 (4.161 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2354\n",
      "INFO:tensorflow:loss = 0.39345145, step = 2500 (4.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.277\n",
      "INFO:tensorflow:loss = 0.30989075, step = 2600 (4.119 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1069\n",
      "INFO:tensorflow:loss = 0.6901599, step = 2700 (4.147 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3078\n",
      "INFO:tensorflow:loss = 0.52883184, step = 2800 (4.114 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0272\n",
      "INFO:tensorflow:loss = 0.25029695, step = 2900 (4.161 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.41223705.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:52:18Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:52:21\n",
      "INFO:tensorflow:Saving dict for global step 3000: acc = 0.4434676, global_step = 3000, loss = 0.5811025\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 3000: ./model-k/model.ckpt-3000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-3000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 3000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.3417027, step = 3000\n",
      "INFO:tensorflow:global_step/sec: 23.8522\n",
      "INFO:tensorflow:loss = 0.32973027, step = 3100 (4.194 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.4698\n",
      "INFO:tensorflow:loss = 0.42106393, step = 3200 (4.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3694\n",
      "INFO:tensorflow:loss = 0.43505046, step = 3300 (4.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5009\n",
      "INFO:tensorflow:loss = 0.49810016, step = 3400 (4.082 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3524\n",
      "INFO:tensorflow:loss = 0.3980983, step = 3500 (4.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4184\n",
      "INFO:tensorflow:loss = 0.3465563, step = 3600 (4.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4238\n",
      "INFO:tensorflow:loss = 0.34246966, step = 3700 (4.095 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2272\n",
      "INFO:tensorflow:loss = 0.5390545, step = 3800 (4.127 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2886\n",
      "INFO:tensorflow:loss = 0.35721043, step = 3900 (4.117 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.3501766.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:53:04Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:53:07\n",
      "INFO:tensorflow:Saving dict for global step 4000: acc = 0.6436367, global_step = 4000, loss = 0.38254964\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4000: ./model-k/model.ckpt-4000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-4000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 4000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.4889041, step = 4000\n",
      "INFO:tensorflow:global_step/sec: 23.6813\n",
      "INFO:tensorflow:loss = 0.4536935, step = 4100 (4.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7835\n",
      "INFO:tensorflow:loss = 0.26364988, step = 4200 (4.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8628\n",
      "INFO:tensorflow:loss = 0.39986348, step = 4300 (4.190 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.7778\n",
      "INFO:tensorflow:loss = 0.24355404, step = 4400 (4.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.1763\n",
      "INFO:tensorflow:loss = 0.3660367, step = 4500 (4.315 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1963\n",
      "INFO:tensorflow:loss = 0.22953308, step = 4600 (4.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7358\n",
      "INFO:tensorflow:loss = 0.27899674, step = 4700 (4.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7343\n",
      "INFO:tensorflow:loss = 0.40095824, step = 4800 (4.213 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3734\n",
      "INFO:tensorflow:loss = 0.32017478, step = 4900 (4.102 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ./model-k/model.ckpt.\n",
      "WARNING:tensorflow:From /home/cs/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n",
      "INFO:tensorflow:Loss for final step: 0.25958282.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:53:51Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:53:54\n",
      "INFO:tensorflow:Saving dict for global step 5000: acc = 0.7076154, global_step = 5000, loss = 0.334831\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5000: ./model-k/model.ckpt-5000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-5000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 5000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.3144574, step = 5000\n",
      "INFO:tensorflow:global_step/sec: 23.9064\n",
      "INFO:tensorflow:loss = 0.14789742, step = 5100 (4.184 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4899\n",
      "INFO:tensorflow:loss = 0.46450394, step = 5200 (4.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4677\n",
      "INFO:tensorflow:loss = 0.16288671, step = 5300 (4.087 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.473\n",
      "INFO:tensorflow:loss = 0.30409804, step = 5400 (4.086 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3717\n",
      "INFO:tensorflow:loss = 0.22272775, step = 5500 (4.103 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4843\n",
      "INFO:tensorflow:loss = 0.2941795, step = 5600 (4.084 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5246\n",
      "INFO:tensorflow:loss = 0.41217393, step = 5700 (4.077 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5187\n",
      "INFO:tensorflow:loss = 0.359841, step = 5800 (4.079 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0559\n",
      "INFO:tensorflow:loss = 0.4283098, step = 5900 (4.157 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.2404609.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:54:37Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:54:40\n",
      "INFO:tensorflow:Saving dict for global step 6000: acc = 0.71605873, global_step = 6000, loss = 0.3301297\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 6000: ./model-k/model.ckpt-6000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-6000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 6000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.22531894, step = 6000\n",
      "INFO:tensorflow:global_step/sec: 23.3914\n",
      "INFO:tensorflow:loss = 0.23757353, step = 6100 (4.277 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1401\n",
      "INFO:tensorflow:loss = 0.4710257, step = 6200 (4.141 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2017\n",
      "INFO:tensorflow:loss = 0.16685632, step = 6300 (4.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9888\n",
      "INFO:tensorflow:loss = 0.31061608, step = 6400 (4.169 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3648\n",
      "INFO:tensorflow:loss = 0.20407298, step = 6500 (4.104 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1852\n",
      "INFO:tensorflow:loss = 0.3441168, step = 6600 (4.135 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 24.3472\n",
      "INFO:tensorflow:loss = 0.29394424, step = 6700 (4.107 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.3959\n",
      "INFO:tensorflow:loss = 0.13413703, step = 6800 (4.099 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2814\n",
      "INFO:tensorflow:loss = 0.14225996, step = 6900 (4.118 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.14366898.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:55:23Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:55:26\n",
      "INFO:tensorflow:Saving dict for global step 7000: acc = 0.74299884, global_step = 7000, loss = 0.28417823\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 7000: ./model-k/model.ckpt-7000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-7000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 7000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.16041309, step = 7000\n",
      "INFO:tensorflow:global_step/sec: 23.4727\n",
      "INFO:tensorflow:loss = 0.2740812, step = 7100 (4.262 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7854\n",
      "INFO:tensorflow:loss = 0.2258652, step = 7200 (4.205 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9322\n",
      "INFO:tensorflow:loss = 0.16791013, step = 7300 (4.179 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.094\n",
      "INFO:tensorflow:loss = 0.106794074, step = 7400 (4.329 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5433\n",
      "INFO:tensorflow:loss = 0.24167266, step = 7500 (4.437 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4933\n",
      "INFO:tensorflow:loss = 0.13440754, step = 7600 (4.446 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.5091\n",
      "INFO:tensorflow:loss = 0.35128948, step = 7700 (4.443 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4574\n",
      "INFO:tensorflow:loss = 0.18690434, step = 7800 (4.452 sec)\n",
      "INFO:tensorflow:global_step/sec: 22.4475\n",
      "INFO:tensorflow:loss = 0.14665276, step = 7900 (4.455 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1473091.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:56:11Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:56:14\n",
      "INFO:tensorflow:Saving dict for global step 8000: acc = 0.7412757, global_step = 8000, loss = 0.3171883\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 8000: ./model-k/model.ckpt-8000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-8000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 8000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.24652967, step = 8000\n",
      "INFO:tensorflow:global_step/sec: 22.854\n",
      "INFO:tensorflow:loss = 0.60698265, step = 8100 (4.378 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7498\n",
      "INFO:tensorflow:loss = 0.26977652, step = 8200 (4.210 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.7323\n",
      "INFO:tensorflow:loss = 0.30375892, step = 8300 (4.214 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.7009\n",
      "INFO:tensorflow:loss = 0.26528156, step = 8400 (4.048 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1704\n",
      "INFO:tensorflow:loss = 0.33460543, step = 8500 (4.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1994\n",
      "INFO:tensorflow:loss = 0.26252687, step = 8600 (4.132 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.0484\n",
      "INFO:tensorflow:loss = 0.3203171, step = 8700 (4.160 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.4342\n",
      "INFO:tensorflow:loss = 0.16059959, step = 8800 (4.091 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.5176\n",
      "INFO:tensorflow:loss = 0.33978117, step = 8900 (4.078 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1755076.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:56:58Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:57:01\n",
      "INFO:tensorflow:Saving dict for global step 9000: acc = 0.7244355, global_step = 9000, loss = 0.31554115\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 9000: ./model-k/model.ckpt-9000\n",
      "INFO:tensorflow:Training model for 1000 steps\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-9000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 9000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.16339824, step = 9000\n",
      "INFO:tensorflow:global_step/sec: 23.24\n",
      "INFO:tensorflow:loss = 0.16344018, step = 9100 (4.304 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.8758\n",
      "INFO:tensorflow:loss = 0.30763447, step = 9200 (4.189 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2057\n",
      "INFO:tensorflow:loss = 0.16073635, step = 9300 (4.131 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1545\n",
      "INFO:tensorflow:loss = 0.32151198, step = 9400 (4.140 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.2703\n",
      "INFO:tensorflow:loss = 0.12782112, step = 9500 (4.120 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1899\n",
      "INFO:tensorflow:loss = 0.24720158, step = 9600 (4.133 sec)\n",
      "INFO:tensorflow:global_step/sec: 23.9113\n",
      "INFO:tensorflow:loss = 0.16404821, step = 9700 (4.185 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1617\n",
      "INFO:tensorflow:loss = 0.304043, step = 9800 (4.137 sec)\n",
      "INFO:tensorflow:global_step/sec: 24.1237\n",
      "INFO:tensorflow:loss = 0.28071544, step = 9900 (4.146 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 10000 into ./model-k/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1452416.\n",
      "INFO:tensorflow:Evaluating model now.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-06-12T20:57:45Z\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [20/200]\n",
      "INFO:tensorflow:Evaluation [40/200]\n",
      "INFO:tensorflow:Evaluation [60/200]\n",
      "INFO:tensorflow:Evaluation [80/200]\n",
      "INFO:tensorflow:Evaluation [100/200]\n",
      "INFO:tensorflow:Evaluation [120/200]\n",
      "INFO:tensorflow:Evaluation [140/200]\n",
      "INFO:tensorflow:Evaluation [160/200]\n",
      "INFO:tensorflow:Evaluation [180/200]\n",
      "INFO:tensorflow:Evaluation [200/200]\n",
      "INFO:tensorflow:Finished evaluation at 2019-06-12-20:57:48\n",
      "INFO:tensorflow:Saving dict for global step 10000: acc = 0.7688172, global_step = 10000, loss = 0.27326548\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10000: ./model-k/model.ckpt-10000\n",
      "INFO:tensorflow:Stop training model as max steps reached\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'acc': 0.7688172, 'loss': 0.27326548, 'global_step': 10000}, [])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it's a magic function :)\n",
    "from tensorflow.contrib.learn.python.learn.learn_io.generator_io import generator_input_fn\n",
    "            \n",
    "train_input_fn = generator_input_fn(\n",
    "    x=data_generator(trainset, hparams, 'train'),\n",
    "    target_key='target',  # you could leave target_key in features, so labels in model_handler will be empty\n",
    "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n",
    "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n",
    ")\n",
    "\n",
    "val_input_fn = generator_input_fn(\n",
    "    x=data_generator(valset, hparams, 'val'),\n",
    "    target_key='target',\n",
    "    batch_size=hparams.batch_size, shuffle=True, num_epochs=None,\n",
    "    queue_capacity=3 * hparams.batch_size + 10, num_threads=1,\n",
    ")\n",
    "            \n",
    "\n",
    "def _create_my_experiment(run_config, hparams):\n",
    "    exp = tf.contrib.learn.Experiment(\n",
    "        estimator=create_model(config=run_config, hparams=hparams),\n",
    "        train_input_fn=train_input_fn,\n",
    "        eval_input_fn=val_input_fn,\n",
    "        train_steps=10000, # just randomly selected params\n",
    "        eval_steps=200,  # read source code for steps-epochs ariphmetics\n",
    "        train_steps_per_iteration=1000,\n",
    "    )\n",
    "    return exp\n",
    "\n",
    "tf.contrib.learn.learn_runner.run(\n",
    "    experiment_fn=_create_my_experiment,\n",
    "    run_config=run_config,\n",
    "    schedule=\"continuous_train_and_eval\",\n",
    "    hparams=hparams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to predict testset and make submission file.\n",
    "\n",
    "1. Create datagenerator and input_function\n",
    "2. Load model\n",
    "3. Iterate over predictions and store results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f5a0fc9e908>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_device_fn': None, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': './model-k'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./model-k/model.ckpt-10000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "158560it [01:12, 2187.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# now we want to predict!\n",
    "paths = glob(os.path.join(DATADIR, 'test/audio/*wav'))\n",
    "\n",
    "\n",
    "\n",
    "def test_data_generator(data):\n",
    "    def generator():\n",
    "        for path in data:\n",
    "            _, wav = wavfile.read(path)\n",
    "            wav = wav.astype(np.float32) / np.iinfo(np.int16).max\n",
    "            fname = os.path.basename(path)\n",
    "            yield dict(\n",
    "                sample=np.string_(fname),\n",
    "                wav=wav,\n",
    "            )\n",
    "\n",
    "    return generator\n",
    "\n",
    "test_input_fn = generator_input_fn(\n",
    "    x=test_data_generator(paths),\n",
    "    batch_size=hparams.batch_size, \n",
    "    shuffle=False, \n",
    "    num_epochs=1,\n",
    "    queue_capacity= 10 * hparams.batch_size, \n",
    "    num_threads=1,\n",
    ")\n",
    "\n",
    "model = create_model(config=run_config, hparams=hparams)\n",
    "it = model.predict(input_fn=test_input_fn)\n",
    "\n",
    "\n",
    "# last batch will contain padding, so remove duplicates\n",
    "submission = dict()\n",
    "for t in tqdm(it):\n",
    "    fname, label = t['sample'].decode(), id2name[t['label']]\n",
    "    submission[fname] = label\n",
    "\n",
    "with open(os.path.join(model_dir, 'submission.csv'), 'w') as fout:\n",
    "    fout.write('fname,label\\n')\n",
    "    for fname, label in submission.items():\n",
    "        fout.write('{},{}\\n'.format(fname, label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### About tf.Estimators\n",
    "\n",
    "#### Pros:\n",
    "\n",
    "* no need to control Session\n",
    "* datagenerator feeds model via queues without explicit queue coding :)\n",
    "* you could naturaly export models into production\n",
    "\n",
    "#### Cons:\n",
    "\n",
    "* it's very hard to debug computational graph (use tf.add_check_numerics() and tf.Print in case of problems)\n",
    "* boilerplate code\n",
    "* need to read source code for making interesting things\n",
    "\n",
    "#### Conclusion: Estimator is a nice abstraction with some boilerplate code :)\n",
    "\n",
    "### About Speech Recognition Challenge:\n",
    "\n",
    "You could start from this end-to-end ipynb, improving several functions for much better results.\n",
    "\n",
    "May the gradient flow be with you."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
