{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam Search\n",
    "\n",
    "Useful resources:\n",
    "\n",
    "* https://machinelearningmastery.com/beam-search-decoder-natural-language-processing/\n",
    "* Taken from wikipedia (https://en.wikipedia.org/wiki/Beam_search):\n",
    "    * In computer science, beam search is a heuristic search algorithm that explores a graph by expanding the most promising node in a limited set. Beam search is an optimization of best-first search that reduces its memory requirements. Best-first search is a graph search which orders all partial solutions (states) according to some heuristic. But in beam search, only a predetermined number of best partial solutions are kept as candidates. It is thus a greedy algorithm.\n",
    "\n",
    "\n",
    "**Why do we need something like beam search?**\n",
    "\n",
    "It is common for models developed for  natural language processing tasks such as caption generation, text summarization, and machine translation to output a probability distribution over each word in the vocabulary for each word in the output sequence. It is then left to a decoder process to transform the probabilities into a final sequence of words. Decoding the most likely output sequence involves searching through all the possible output sequences based on their likelihood. The size of the vocabulary is often tens or hundreds of thousands of words, or even millions of words. Therefore, the search problem is exponential in the length of the output sequence and is intractable (NP-complete) to search completely. Candidate sequences of words are scored based on their likelihood. It is common to use a greedy search or a beam search to locate candidate sequences of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy Search Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from math import log\n",
    "\n",
    "# define a sequence of 10 words over a vocab of 5 words\n",
    "data = [[0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "        [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "        [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "        [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        [0.5, 0.4, 0.3, 0.2, 0.1],\n",
    "        [0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "        [0.5, 0.4, 0.3, 0.2, 0.1]]\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# greedy decoder only gives you one candidate\n",
    "# beam search decoder gives you k candidates\n",
    "def greedy_decoder(data):\n",
    "    # index for largest probability each row\n",
    "    # argmax: returns indices of the maximum values along an axis.\n",
    "    return [np.argmax(s) for s in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 0, 4, 0, 4, 0, 4, 0, 4, 0]\n"
     ]
    }
   ],
   "source": [
    "# decode sequence\n",
    "result = greedy_decoder(data)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beam Search Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# beam search\n",
    "\n",
    "'''\n",
    "Issues with this code:\n",
    "\n",
    "1. \n",
    "\n",
    "I’m not sure I understand why the example multiplies\n",
    "log probabilities. Aren’t log probabilities normally \n",
    "added together to get the equivalent of multiplied \n",
    "real-value scalar probabilities?\n",
    "\n",
    "\n",
    "0.5 * 0.5 * 0.25 = 0.0625\n",
    "\n",
    "log(0.5) + log(0.5) + log(0.25) = -2.772588722239781\n",
    "exp(-2.772588722239781) == 0.0624\n",
    "\n",
    "whereas:\n",
    "log(0.5) * log(0.5) * log(0.25) = -0.6660493039778589\n",
    "exp(-0.6660493039778589) =~ 0.51374 != 0.625 ??\n",
    "\n",
    "2.\n",
    "\n",
    "Another issue with the code is the line\n",
    "” for j in range(len(row))”\n",
    "\n",
    "You’re iterating over all the data in row. \n",
    "In a typical text generation problem, there is a huge \n",
    "amount of words in a vocabulary, we probably don’t\n",
    "want to iterate over all of them? Rather we would \n",
    "be interested in only top k probabilities.\n",
    "\n",
    "3. \n",
    "\n",
    "Another problem is that log(1) = 0, so \n",
    "prod( log(p_i) ) ~ 0 for any sequence containing \n",
    "any character that is predicted with probability close to 1.0.\n",
    "\n",
    "Ultimately, this leading to a pathological degeneracy of \n",
    "solutions during inference. In my results, it manifested \n",
    "itself as long runs of newline characters.\n",
    "\n",
    "'''\n",
    "\n",
    "def beam_search_decoder(data, k):\n",
    "    sequences = [[list(), 1.0]]\n",
    "    # walk over each step in sequence\n",
    "    for row in data:\n",
    "        all_candidates = list()\n",
    "        # expand each current candidate\n",
    "        for i in range(len(sequences)):\n",
    "            seq, score = sequences[i]\n",
    "            for j in range(len(row)):\n",
    "                candidate = [seq + [j], score * -log(row[j])]\n",
    "                all_candidates.append(candidate)\n",
    "        # order all candidates by score\n",
    "        ordered = sorted(all_candidates, key=lambda tup:tup[1])\n",
    "        # select k best\n",
    "        sequences = ordered[:k]\n",
    "    return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 0, 4, 0, 4, 0, 4, 0, 4, 0], 0.025600863289563108]\n",
      "[[4, 0, 4, 0, 4, 0, 4, 0, 4, 1], 0.03384250043584397]\n",
      "[[4, 0, 4, 0, 4, 0, 4, 0, 3, 0], 0.03384250043584397]\n"
     ]
    }
   ],
   "source": [
    "# Perform beam search and give me k=3 candidates\n",
    "# with the highest likelihood\n",
    "result = beam_search_decoder(data, 3)\n",
    "# print result\n",
    "for seq in result:\n",
    "    print(seq)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
