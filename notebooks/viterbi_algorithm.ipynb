{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viterbi Algorithm\n",
    "\n",
    "Useful resources:\n",
    "\n",
    "* Wikipedia article with example: https://en.wikipedia.org/wiki/Viterbi_algorithm\n",
    "* Viterbi Algorithm Clarified (same example as wikipedia): http://blog.ivank.net/viterbi-algorithm-clarified.html\n",
    "* Short explanation and runtime behaviour: http://www.cs.toronto.edu/~sengels/tutorials/viterbi.html\n",
    "* A Tutorial on Convolutional Coding with Viterbi Decoding: http://home.netcom.com/~chip.f/viterbi/tutorial.html\n",
    "* https://jyyuan.wordpress.com/2014/01/22/viterbi-algorithm-finding-most-likely-sequence-in-hmm/\n",
    "\n",
    "This notebook is using the example from the above mentioned wikipedia article. The viterbi algorithm is used in the decoding step when used in conjunction with Hidden Markov Models (HMMs).\n",
    "\n",
    "\n",
    "## Input\n",
    "\n",
    "* The **observation space** $O = \\{o_1, o2,...,o_N\\}$\n",
    "* The **state space** $S = \\{ s_1, s_2,...,s_K\\}$\n",
    "* An array of **initial probabilities** $\\Pi = ( \\pi_1, \\pi_2,...,\\pi_K )$ such that $\\pi_i$ stores the probability that $x_1 == s_i$\n",
    "* A **sequence of observations** $Y = (y_1,y_2,...,y_T)$ such that $y_t == i$ if the observation at time $t$ is $o_i$\n",
    "* **Transition probability matrix A** of size $K \\times K$ such that $A_{ij}$ stores the transition probability of transiting from state $s_i$ to state $s_j$\n",
    "* **Observation likelihoods / Emission probability matrix B** of size $K \\times N$ such that $B_{ij}$ stores the probability of observing $o_j$ from state $s_i$\n",
    "\n",
    "\n",
    "\n",
    "## Output\n",
    "\n",
    "* The most likely hidden state sequence $X = (x_1,x_2,...,x_N)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doctor example\n",
    "\n",
    "Consider a village where all villagers are either **healthy** or have a **fever** and only the village doctor can determine whether each has a fever. The doctor diagnoses fever by asking patients how they feel. The villagers may only answer that they feel **normal, dizzy, or cold**.\n",
    "\n",
    "The doctor believes that the health condition of his patients operate as a discrete Markov chain. There are two states, **\"Healthy\" and \"Fever\"**, but the doctor cannot observe them **directly**; they are **hidden** from him. On each day, there is a certain chance that the patient will tell the doctor he/she is **\"normal\", \"cold\", or \"dizzy\"**, depending on their health condition.\n",
    "\n",
    "The observations (normal, cold, dizzy) along with a hidden state (healthy, fever) form a hidden Markov model (HMM).\n",
    "\n",
    "![HMM Example](images/An_example_of_HMM.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# *** Observations/Emissions ***\n",
    "#\n",
    "# What you can actually measure/see/observe\n",
    "obs = ('normal', 'cold', 'dizzy')\n",
    "\n",
    "\n",
    "# *** Hidden states ***\n",
    "#\n",
    "# States which you cannot measure/see/observe\n",
    "# and cause the observations/emissions.\n",
    "# Same concept as latent variables?\n",
    "states = ('Healthy', 'Fever')\n",
    "\n",
    "# ** Start probability ***\n",
    "#\n",
    "# start_probability represents the doctor's belief about \n",
    "# which state the HMM is in when the patient first visits \n",
    "# (all he knows is that the patient tends to be healthy). \n",
    "# The particular probability distribution used here is not \n",
    "# the equilibrium one, which is (given the transition \n",
    "# probabilities) approximately {'Healthy': 0.57, 'Fever': 0.43}\n",
    "start_p = {'Healthy': 0.6, 'Fever': 0.4}\n",
    "\n",
    "# *** Transition probability***\n",
    "#\n",
    "#\n",
    "#\n",
    "trans_p = {\n",
    "   'Healthy' : {'Healthy': 0.7, 'Fever': 0.3},\n",
    "   'Fever' : {'Healthy': 0.4, 'Fever': 0.6}\n",
    "   }\n",
    "\n",
    "# *** Emission probability***\n",
    "# \n",
    "#\n",
    "#\n",
    "emit_p = {\n",
    "   'Healthy' : {'normal': 0.5, 'cold': 0.4, 'dizzy': 0.1},\n",
    "   'Fever' : {'normal': 0.1, 'cold': 0.3, 'dizzy': 0.6}\n",
    "   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def viterbi(obs, states, start_p, trans_p, emit_p):\n",
    "    V = [{}]\n",
    "    for st in states:\n",
    "        V[0][st] = {\"prob\": start_p[st] * emit_p[st][obs[0]], \"prev\": None}\n",
    "    # Run Viterbi when t > 0\n",
    "    for t in range(1, len(obs)):\n",
    "        V.append({})\n",
    "        for st in states:\n",
    "            max_tr_prob = max(V[t-1][prev_st][\"prob\"]*trans_p[prev_st][st] for prev_st in states)\n",
    "            for prev_st in states:\n",
    "                if V[t-1][prev_st][\"prob\"] * trans_p[prev_st][st] == max_tr_prob:\n",
    "                    max_prob = max_tr_prob * emit_p[st][obs[t]]\n",
    "                    V[t][st] = {\"prob\": max_prob, \"prev\": prev_st}\n",
    "                    break\n",
    "    for line in dptable(V):\n",
    "        print(line)\n",
    "    opt = []\n",
    "    # The highest probability\n",
    "    max_prob = max(value[\"prob\"] for value in V[-1].values())\n",
    "    previous = None\n",
    "    # Get most probable state and its backtrack\n",
    "    for st, data in V[-1].items():\n",
    "        if data[\"prob\"] == max_prob:\n",
    "            opt.append(st)\n",
    "            previous = st\n",
    "            break\n",
    "    # Follow the backtrack till the first observation\n",
    "    for t in range(len(V) - 2, -1, -1):\n",
    "        opt.insert(0, V[t + 1][previous][\"prev\"])\n",
    "        previous = V[t + 1][previous][\"prev\"]\n",
    "\n",
    "    print('The steps of states are ' + ' '.join(opt) + ' with highest probability of %s' % max_prob)\n",
    "\n",
    "def dptable(V):\n",
    "    # Print a table of steps from dictionary\n",
    "    yield \" \".join((\"%12d\" % i) for i in range(len(V)))\n",
    "    for state in V[0]:\n",
    "        yield \"%.7s: \" % state + \" \".join(\"%.7s\" % (\"%f\" % v[state][\"prob\"]) for v in V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0            1            2\n",
      "Healthy: 0.30000 0.08400 0.00588\n",
      "Fever: 0.04000 0.02700 0.01512\n",
      "The steps of states are Healthy Healthy Fever with highest probability of 0.01512\n"
     ]
    }
   ],
   "source": [
    "viterbi(obs,\n",
    "        states,\n",
    "        start_p,\n",
    "        trans_p,\n",
    "        emit_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Copied from: https://github.com/WuLC/ViterbiAlgorithm/blob/master/Viterbi.py\n",
    "\n",
    "def viterbi_2(obs, states, s_pro, t_pro, e_pro):\n",
    "    path = { s:[] for s in states} # init path: path[s] represents the path ends with s\n",
    "    curr_pro = {}\n",
    "    for s in states:\n",
    "        curr_pro[s] = s_pro[s]*e_pro[s][obs[0]]\n",
    "    for i in range(1, len(obs)):\n",
    "        last_pro = curr_pro\n",
    "        curr_pro = {}\n",
    "        for curr_state in states:\n",
    "            max_pro, last_sta = max(((last_pro[last_state]*t_pro[last_state][curr_state]*e_pro[curr_state][obs[i]], last_state) \n",
    "                                       for last_state in states))\n",
    "            curr_pro[curr_state] = max_pro\n",
    "            path[curr_state].append(last_sta)\n",
    "\n",
    "    # find the final largest probability\n",
    "    max_pro = -1\n",
    "    max_path = None\n",
    "    for s in states:\n",
    "        path[s].append(s)\n",
    "        if curr_pro[s] > max_pro:\n",
    "            max_path = path[s]\n",
    "            max_pro = curr_pro[s]\n",
    "        # print '%s: %s'%(curr_pro[s], path[s]) # different path and their probability\n",
    "    return max_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Healthy', 'Healthy', 'Fever']\n"
     ]
    }
   ],
   "source": [
    "print(viterbi_2(obs, states, start_p, trans_p, emit_p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reveals that the observations ['normal', 'cold', 'dizzy'] were most likely generated by states ['Healthy', 'Healthy', 'Fever']. In other words, given the observed activities, the patient was most likely to have been healthy both on the first day when he felt normal as well as on the second day when he felt cold, and then he contracted a fever the third day.\n",
    "\n",
    "The operation of Viterbi's algorithm can be visualized by means of a trellis diagram. The Viterbi path is essentially the shortest path through this trellis. The trellis for the clinic example is shown below; the corresponding Viterbi path is in bold:\n",
    "\n",
    "![HMM Example](images/Viterbi_animated_demo.gif)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
